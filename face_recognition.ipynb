{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plt_show function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_show(image, title=\"\"):\n",
    "    if np.ndim(image) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(image, cmap='Greys_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FaceDetection and VideoCamera class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetection(object):\n",
    "    def __init__(self, xml_path):\n",
    "        self.face_cascade = cv2.CascadeClassifier(xml_path)\n",
    "        \n",
    "    def detect(self, frame):\n",
    "        gray = frame\n",
    "        if np.ndim(frame) == 3:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        face = self.face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoCamera(object):\n",
    "    def __init__(self, index=0):\n",
    "        self.webcam = cv2.VideoCapture(index)\n",
    "        self.index = index\n",
    "        print(self.webcam.isOpened())\n",
    "        \n",
    "    def get_frame(self, gray=False):\n",
    "        _, frame = self.webcam.read()\n",
    "        if gray:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        return frame\n",
    "    \n",
    "    def delete(self):\n",
    "        self.webcam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(self.webcam.isOpened())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Normalization\n",
    "-  Cut the face\n",
    "-  Normalized pixel intensity\n",
    "-  Resize face image\n",
    "-  Align face image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cut the faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_faces(image, face_cord):\n",
    "    faces = []\n",
    "    \n",
    "    for x, y, w, h in face_cord:\n",
    "        w_rm = int(0.1 * w/2)\n",
    "#         print(w_rm)\n",
    "        faces.append(image[y:y+h, x+w_rm:x+w-w_rm])\n",
    "    \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Normalized pixel intensity\n",
    "1. convert image from rgb to gray\n",
    "2. contrast enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(images):\n",
    "    images_norm = []\n",
    "    \n",
    "    for image in images:\n",
    "        if np.ndim(image) == 3:\n",
    "            images_norm.append(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "        else:\n",
    "            # contrast pixel intensity\n",
    "            images_norm.append(cv2.equalizeHist(image))\n",
    "    return images_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(frames, size=(50, 50)):\n",
    "    image_resize = []\n",
    "    \n",
    "    for frame in frames:\n",
    "        if frame.shape < size:\n",
    "            img = cv2.resize(frame, size, interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            img = cv2.resize(frame, size, interpolation=cv2.INTER_CUBIC)\n",
    "        image_resize.append(img)\n",
    "    \n",
    "    return image_resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Align Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all function together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_images(image, face):\n",
    "    cut = cut_faces(image, face)\n",
    "    norm = normalized(cut)\n",
    "    res = resize(norm)\n",
    "    return res;\n",
    "\n",
    "# draw rectangle around face\n",
    "def drawRect(image, face):\n",
    "    for x, y, w, h in face:\n",
    "        w_rmv = int(0.2 * w/2)\n",
    "        cv2.rectangle(image, (x+w_rmv, y), (x+w-w_rmv, y+h), (0, 0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset of 30 face each person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "cwd = '/media/rohitkumar/Rohit-Sonu/python3/projects/Face_Recognition'\n",
    "folder = cwd+'/people/'+ input('Person name: ').lower()\n",
    "\n",
    "webcam = VideoCamera(0)\n",
    "detector = FaceDetection('/media/rohitkumar/Rohit-Sonu/python3/projects/Face_Recognition/haarcascade_frontalface_default.xml')\n",
    "       \n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "    counter = 0\n",
    "    timer = 0\n",
    "    \n",
    "     \n",
    "    while counter<50:\n",
    "    \n",
    "        frame = webcam.get_frame()\n",
    "        face_coord = detector.detect(frame)\n",
    "        \n",
    "        if len(face_coord) and timer%700 == 50:\n",
    "            norm_frame = normalized_images(frame, face_coord)\n",
    "            cv2.imwrite(folder+'/'+str(counter)+'.jpg', norm_frame[0])\n",
    "            plt_show(norm_frame[0])\n",
    "            clear_output(wait=True)\n",
    "            counter += 1\n",
    "        drawRect(frame, face_coord)\n",
    "        cv2.imshow(\"Face\", frame)\n",
    "        \n",
    "        cv2.waitKey(50)\n",
    "        timer += 50\n",
    "    webcam.delete()\n",
    "else:\n",
    "    print('user already exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "_recognizer.train(image, label)_\n",
    "\n",
    "-  images: list of numpy arrays\n",
    "-  labels: numpy array with the label corresponding to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_dic = {}\n",
    "    \n",
    "    persons = [person for person in os.listdir('people/')]\n",
    "    \n",
    "    for idx, person in enumerate(persons):\n",
    "        label_dic[idx] = person\n",
    "        \n",
    "        for img in os.listdir('people/'+person):\n",
    "            images.append(cv2.imread('people/'+person+'/'+img, 0))\n",
    "            labels.append(idx)\n",
    "            \n",
    "    return (images, np.array(labels), label_dic)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, label_dic = collect_dataset()\n",
    "\n",
    "# train eigen model\n",
    "eig_rec = cv2.face.EigenFaceRecognizer_create()\n",
    "eig_rec.train(images, labels)\n",
    "\n",
    "# train fisher model\n",
    "fish_rec = cv2.face.FisherFaceRecognizer_create()\n",
    "fish_rec.train(images, labels)\n",
    "\n",
    "# train LBPHF model\n",
    "lbphf = cv2.face.LBPHFaceRecognizer_create()\n",
    "lbphf.train(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict faces\n",
    "\n",
    "-  pred, conf = recognizer.train(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on still images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rohit 3027.278560467097\n",
      "Rohit 159.59568745909917\n",
      "Rohit 134.797004927861\n"
     ]
    }
   ],
   "source": [
    "detector = FaceDetection('/media/rohitkumar/Rohit-Sonu/python3/projects/Face_Recognition/haarcascade_frontalface_default.xml')\n",
    "frame = cv2.imread('../my_face.png', 0)\n",
    "face_coord = detector.detect(frame)\n",
    "\n",
    "norm_images = normalized_images(frame, face_coord)\n",
    "# collector = cv2.face.MinDistancePredictCollector()\n",
    "pred, conf = eig_rec.predict(norm_images[0])\n",
    "print(label_dic[pred].capitalize(), conf)\n",
    "# conf = collector.getDist()\n",
    "# predict = collector.getLabel()\n",
    "\n",
    "pred, conf = fish_rec.predict(norm_images[0])\n",
    "print(label_dic[pred].capitalize(), conf)\n",
    "\n",
    "pred, conf = lbphf.predict(norm_images[0])\n",
    "print(label_dic[pred].capitalize(), conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on live videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "webcam = VideoCamera(0)\n",
    "detector = FaceDetection('/media/rohitkumar/Rohit-Sonu/python3/projects/Face_Recognition/haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    frame = webcam.get_frame()\n",
    "    face_coord = detector.detect(frame)\n",
    "    \n",
    "    if len(face_coord):\n",
    "        norm_frame = normalized_images(frame, face_coord)\n",
    "        thershold = 140\n",
    "        for i, face in enumerate(norm_frame):\n",
    "            pred, conf = lbphf.predict(face)\n",
    "            \n",
    "            if conf < thershold:\n",
    "                cv2.putText(frame, label_dic[pred].capitalize(), (face_coord[i][0] , face_coord[i][1]-10),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Unknown\".capitalize(), (face_coord[i][0] , face_coord[i][1]-10),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 2)\n",
    "    drawRect(frame, face_coord)\n",
    "    cv2.imshow(\"Face Recognizer\", frame)\n",
    "#     print(label_dic[pred].capitalize())\n",
    "    \n",
    "    if cv2.waitKey(20) & 0xff == 27:\n",
    "        break;\n",
    "webcam.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
